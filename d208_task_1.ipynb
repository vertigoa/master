{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Performance Assessment: D208 Predictive Modeling Task 1 - Multiple Linear Regression.\n",
    "\n",
    "## Michael Hindes\n",
    "Department of Information Technology, Western Governors University\n",
    "<br>D208: Predictive Modeling\n",
    "<br>Professor David Gagner\n",
    "<br>February 11, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to understanding the exact relationship between a response and predictor variables and to create a multiple regression model derived from medical raw data, targeting a business question reflective of a real-world organizational challenge. Python is employed to conduct a multiple regression analysis to explore the research question thoroughly. The analysis is supported by visual aids to elucidate the regression outcomes and predictions. The process also involves meticulous data cleaning to ensure accuracy and reliability. Additionally, the project shares the code used for the regression analysis and predictions. It concludes by detailing the regression equation, evaluating the statistical and practical significances, discussing limitations, and suggesting possible actions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Research Question\n",
    "## Describe the purpose of this data analysis by doing the following::\n",
    "\n",
    "### **A1. Research Question:**\n",
    "**\"What factors contribute to the total charges incurred by patients during their hospital stay?\"**\n",
    "\n",
    "This question aims to identify key variables within the dataset that influence hospital charges, including length of stay, services rendered, patient risk factors, and demographic details. The goal is to understand the primary drivers of hospital expenses. This information can be used to help predict charges for future patients, allowing hospitals to better manage their resources and improve patient care.\n",
    "\n",
    "### **A2. Define the goals of the data analysis.**\n",
    "\n",
    "This data analysis project is focused on developing a predictive model as a practical \n",
    "tool to help healthcare organizations in planning and operational improvements. By \n",
    "examining a wide range of factors that potentially affect TotalCharge, the project \n",
    "aims to build a model that supports data-driven decision-making in healthcare. This \n",
    "initiative represents a preliminary step towards leveraging predictive modeling for \n",
    "financial sustainability and greater transparency.\n",
    "\n",
    "-   Variable Identification: Identify a comprehensive set of factors that influence \n",
    "TotalCharge, with a focus on clinical, operational, and demographic elements. This \n",
    "step lays the groundwork for understanding the broad variables that could impact \n",
    "hospital charges.\n",
    "\n",
    "-   Quantitative Assessment: Conduct a quantitative analysis to evaluate how these \n",
    "factors contribute to TotalCharge. This will help in understanding the significance \n",
    "and relationships of different variables with TotalCharge, providing a basis for the \n",
    "predictive model.\n",
    "\n",
    "-   Insight Generation: The aim is to generate preliminary insights that could inform \n",
    "hospital cost management and pricing strategies, potentially leading to improved \n",
    "operational and billing processes. These insights are seen as an initial foray into \n",
    "optimizing hospital operations.\n",
    "\n",
    "-   Predictive Modeling: The core goal is to develop an initial predictive model that \n",
    "estimates TotalCharge based on factors identifiable prior to or at the point of \n",
    "admission. This model is intended to enhance financial planning and increase \n",
    "transparency for both the hospital and its patients, serving as a first step towards \n",
    "more sophisticated predictive capabilities in the future.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "project",
     "sectionA"
    ]
   },
   "source": [
    "# Part II: Method Justification\n",
    "\n",
    "## B. Describe multiple linear regression methods by doing the following:\n",
    "\n",
    "### **B1. Summarize four assumptions of a multiple linear regression model:**\n",
    "\n",
    "In multiple linear regression analysis, four key assumptions are critical: linearity between variables, independence of observations, constant error variance (homoscedasticity), and normal distribution of error terms. Understanding and checking these assumptions is essential for the model's reliability and accuracy, providing a solid basis for predictive analytics.\n",
    "\n",
    "-   Linearity asserts that there is a straight-line relationship between each predictor (independent variable) and the response (dependent variable). This means that changes in a predictor variable are associated with proportional changes in the response variable.\n",
    "\n",
    "-   Independence of Observations indicates that the data points in the dataset do not influence each other. Each observation's response is determined by its predictor values, free from the effects of other observations in the dataset.\n",
    "\n",
    "-   Homoscedasticity refers to the requirement that the error terms (differences between observed and predicted values) maintain a consistent variance across all levels of the independent variables. This constant variance ensures that the model's accuracy does not depend on the value of the predictors.\n",
    "\n",
    "-    Normality of Errors involves the assumption that for any fixed value of an independent variable, the error terms are normally distributed. This normal distribution is central to conducting various statistical tests on the model's coefficients to determine their significance.\n",
    "\n",
    "(Statology, n.d.)\n",
    "(Pennsylvania State University, n.d.)\n",
    "\n",
    "### **B2. Describe two benefits of using Python for data analysis:**\n",
    "\n",
    "- **Rich Libraries:** ALthough R was designed for statistics and data, Python offers comprehensive libraries such as Pandas for data manipulation, NumPy for numerical computations, Matplotlib and Seaborn for visualization, and Scikit-learn for machine learning, facilitating a wide range of data analysis tasks.\n",
    "- **Versatility and Support:** Python's syntax is intuitive and readable, making it accessible for and versatile for various tasks beyond data analysis. The extensive community support ensures abundant resources for troubleshooting and learning. Deep learning AI .ect.\n",
    "- **Familiarity and Broader reach** Python's ...\n",
    "\n",
    "### **B3. Explain why multiple linear regression is an appropriate technique for analyzing the research question summarized in part I:**\n",
    "\n",
    "Multiple linear regression is appropriate for exploring the research question because it enables the identification and quantification of relationships between a continuous response variable (Total Charges) and multiple predictor variables. This method allows for the analysis of how individual factors, such as length of hospital stay, patient demographics, and received services, collectively influence the total hospital charges, providing insights needed for predictive modeling and decision-making in this healthcare context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Data Preparation\n",
    "\n",
    "## C. Summarize the data preparation process for multiple linear regression analysis by doing the following:\n",
    "\n",
    "### *C1. Describe your data cleaning goals and the steps used to clean the data to achieve the goals that align with your research question including your annotated code.**\n",
    "\n",
    "*   **Importing the Data**: Use`pd.read_csv()` to import data into a Pandas DataFrame.\n",
    "    \n",
    "*   **Initial Data Examination**: Using `df.head()` provides a quick snapshot of the dataset, including a view of the first few rows. This helps in getting a preliminary understanding of the data's structure and content.\n",
    "    \n",
    "*   **Checking Data Types**: The `df.info()` method is used for assessing the dataset's overall structure, including the data types of each column and the presence of non-null values. \n",
    "    \n",
    "*   **Identifying Duplicate Rows**: Utilizing `df.duplicated()` to find duplicate rows is an essential cleaning step. Duplicates can skew your analysis and lead to inaccurate models. Once identified, you can decide whether to remove these rows with `df.drop_duplicates()` depending on their relevance to your research question.\n",
    "    \n",
    "*   **Detecting Missing Values**: The `df.isnull().sum()` command is instrumental in identifying missing values across the dataset. Understanding where and how much data is missing is critical for deciding on imputation methods or if certain rows/columns should be excluded from the analysis.\n",
    "\n",
    "\n",
    "\n",
    "MAybe later: *   **Reviewing Unique Values**: Although `df.unique()` is used to explore unique values in a Series, for dataframes, you might consider `df.nunique()` to see the number of unique values in each column or use `df['column_name'].unique()` to check unique values in specific columns. This step is valuable for understanding the diversity of information within your dataset, particularly for categorical data.\n",
    "\n",
    "\n",
    "follow the slides here: https://westerngovernorsuniversity.sharepoint.com/:p:/r/sites/DataScienceTeam/_layouts/15/Doc.aspx?sourcedoc=%7B285C378F-8089-4758-9ABE-29976D079B56%7D&file=Dr.%20Sewell%20D208_Predictive_Modeling_Webinar_Episode%201t.pptx&action=edit&mobileredirect=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (842801469.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python.exe -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from missingno) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from missingno) (3.8.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from missingno) (1.12.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from missingno) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hinde\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->missingno) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->missingno) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hinde\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn->missingno) (2.2.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hinde\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Jinja2 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hinde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# Import packages and libraries\n",
    "%pip install scikit-learn\n",
    "%pip install missingno\n",
    "%pip install Jinja2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>UID</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Population</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalCharge</th>\n",
       "      <th>Additional_charges</th>\n",
       "      <th>Item1</th>\n",
       "      <th>Item2</th>\n",
       "      <th>Item3</th>\n",
       "      <th>Item4</th>\n",
       "      <th>Item5</th>\n",
       "      <th>Item6</th>\n",
       "      <th>Item7</th>\n",
       "      <th>Item8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CaseOrder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C412403</td>\n",
       "      <td>8cd49b13-f45a-4b47-a2bd-173ffa932c2f</td>\n",
       "      <td>3a83ddb66e2ae73798bdf1d705dc0932</td>\n",
       "      <td>Eva</td>\n",
       "      <td>AL</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>35621</td>\n",
       "      <td>34.34960</td>\n",
       "      <td>-86.72508</td>\n",
       "      <td>2951</td>\n",
       "      <td>...</td>\n",
       "      <td>3726.702860</td>\n",
       "      <td>17939.403420</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z919181</td>\n",
       "      <td>d2450b70-0337-4406-bdbb-bc1037f1734c</td>\n",
       "      <td>176354c5eef714957d486009feabf195</td>\n",
       "      <td>Marianna</td>\n",
       "      <td>FL</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>32446</td>\n",
       "      <td>30.84513</td>\n",
       "      <td>-85.22907</td>\n",
       "      <td>11303</td>\n",
       "      <td>...</td>\n",
       "      <td>4193.190458</td>\n",
       "      <td>17612.998120</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F995323</td>\n",
       "      <td>a2057123-abf5-4a2c-abad-8ffe33512562</td>\n",
       "      <td>e19a0fa00aeda885b8a436757e889bc9</td>\n",
       "      <td>Sioux Falls</td>\n",
       "      <td>SD</td>\n",
       "      <td>Minnehaha</td>\n",
       "      <td>57110</td>\n",
       "      <td>43.54321</td>\n",
       "      <td>-96.63772</td>\n",
       "      <td>17125</td>\n",
       "      <td>...</td>\n",
       "      <td>2434.234222</td>\n",
       "      <td>17505.192460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A879973</td>\n",
       "      <td>1dec528d-eb34-4079-adce-0d7a40e82205</td>\n",
       "      <td>cd17d7b6d152cb6f23957346d11c3f07</td>\n",
       "      <td>New Richland</td>\n",
       "      <td>MN</td>\n",
       "      <td>Waseca</td>\n",
       "      <td>56072</td>\n",
       "      <td>43.89744</td>\n",
       "      <td>-93.51479</td>\n",
       "      <td>2162</td>\n",
       "      <td>...</td>\n",
       "      <td>2127.830423</td>\n",
       "      <td>12993.437350</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C544523</td>\n",
       "      <td>5885f56b-d6da-43a3-8760-83583af94266</td>\n",
       "      <td>d2f0425877b10ed6bb381f3e2579424a</td>\n",
       "      <td>West Point</td>\n",
       "      <td>VA</td>\n",
       "      <td>King William</td>\n",
       "      <td>23181</td>\n",
       "      <td>37.59894</td>\n",
       "      <td>-76.88958</td>\n",
       "      <td>5287</td>\n",
       "      <td>...</td>\n",
       "      <td>2113.073274</td>\n",
       "      <td>3716.525786</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Customer_id                           Interaction  \\\n",
       "CaseOrder                                                     \n",
       "1             C412403  8cd49b13-f45a-4b47-a2bd-173ffa932c2f   \n",
       "2             Z919181  d2450b70-0337-4406-bdbb-bc1037f1734c   \n",
       "3             F995323  a2057123-abf5-4a2c-abad-8ffe33512562   \n",
       "4             A879973  1dec528d-eb34-4079-adce-0d7a40e82205   \n",
       "5             C544523  5885f56b-d6da-43a3-8760-83583af94266   \n",
       "\n",
       "                                        UID          City State        County  \\\n",
       "CaseOrder                                                                       \n",
       "1          3a83ddb66e2ae73798bdf1d705dc0932           Eva    AL        Morgan   \n",
       "2          176354c5eef714957d486009feabf195      Marianna    FL       Jackson   \n",
       "3          e19a0fa00aeda885b8a436757e889bc9   Sioux Falls    SD     Minnehaha   \n",
       "4          cd17d7b6d152cb6f23957346d11c3f07  New Richland    MN        Waseca   \n",
       "5          d2f0425877b10ed6bb381f3e2579424a    West Point    VA  King William   \n",
       "\n",
       "             Zip       Lat       Lng  Population  ...  TotalCharge  \\\n",
       "CaseOrder                                         ...                \n",
       "1          35621  34.34960 -86.72508        2951  ...  3726.702860   \n",
       "2          32446  30.84513 -85.22907       11303  ...  4193.190458   \n",
       "3          57110  43.54321 -96.63772       17125  ...  2434.234222   \n",
       "4          56072  43.89744 -93.51479        2162  ...  2127.830423   \n",
       "5          23181  37.59894 -76.88958        5287  ...  2113.073274   \n",
       "\n",
       "          Additional_charges Item1  Item2  Item3  Item4 Item5 Item6 Item7  \\\n",
       "CaseOrder                                                                   \n",
       "1               17939.403420     3      3      2      2     4     3     3   \n",
       "2               17612.998120     3      4      3      4     4     4     3   \n",
       "3               17505.192460     2      4      4      4     3     4     3   \n",
       "4               12993.437350     3      5      5      3     4     5     5   \n",
       "5                3716.525786     2      1      3      3     5     3     4   \n",
       "\n",
       "           Item8  \n",
       "CaseOrder         \n",
       "1              4  \n",
       "2              3  \n",
       "3              3  \n",
       "4              5  \n",
       "5              3  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data and read it into a dataframe, set index to the first column\n",
    "df = pd.read_csv('D208_templates/medical_clean.csv', index_col=0)\n",
    "\n",
    "# Set the maximum number of columns to display to 6 to save space for exersize\n",
    "# pd.set_option('display.max_columns', 6)\n",
    "\n",
    "# Display the first five rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>UID</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Population</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalCharge</th>\n",
       "      <th>Additional_charges</th>\n",
       "      <th>Item1</th>\n",
       "      <th>Item2</th>\n",
       "      <th>Item3</th>\n",
       "      <th>Item4</th>\n",
       "      <th>Item5</th>\n",
       "      <th>Item6</th>\n",
       "      <th>Item7</th>\n",
       "      <th>Item8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CaseOrder</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>B863060</td>\n",
       "      <td>a25b594d-0328-486f-a9b9-0567eb0f9723</td>\n",
       "      <td>39184dc28cc038871912ccc4500049e5</td>\n",
       "      <td>Norlina</td>\n",
       "      <td>NC</td>\n",
       "      <td>Warren</td>\n",
       "      <td>27563</td>\n",
       "      <td>36.42886</td>\n",
       "      <td>-78.23716</td>\n",
       "      <td>4762</td>\n",
       "      <td>...</td>\n",
       "      <td>6850.942</td>\n",
       "      <td>8927.642</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>P712040</td>\n",
       "      <td>70711574-f7b1-4a17-b15f-48c54564b70f</td>\n",
       "      <td>3cd124ccd43147404292e883bf9ec55c</td>\n",
       "      <td>Milmay</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>8340</td>\n",
       "      <td>39.43609</td>\n",
       "      <td>-74.87302</td>\n",
       "      <td>1251</td>\n",
       "      <td>...</td>\n",
       "      <td>7741.690</td>\n",
       "      <td>28507.150</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>R778890</td>\n",
       "      <td>1d79569d-8e0f-4180-a207-d67ee4527d26</td>\n",
       "      <td>41b770aeee97a5b9e7f69c906a8119d7</td>\n",
       "      <td>Southside</td>\n",
       "      <td>TN</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>37171</td>\n",
       "      <td>36.36655</td>\n",
       "      <td>-87.29988</td>\n",
       "      <td>532</td>\n",
       "      <td>...</td>\n",
       "      <td>8276.481</td>\n",
       "      <td>15281.210</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>E344109</td>\n",
       "      <td>f5a68e69-2a60-409b-a92f-ac0847b27db0</td>\n",
       "      <td>2bb491ef5b1beb1fed758cc6885c167a</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>SD</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>57775</td>\n",
       "      <td>44.10354</td>\n",
       "      <td>-102.01590</td>\n",
       "      <td>271</td>\n",
       "      <td>...</td>\n",
       "      <td>7644.483</td>\n",
       "      <td>7781.678</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>I569847</td>\n",
       "      <td>bc482c02-f8c9-4423-99de-3db5e62a18d5</td>\n",
       "      <td>95663a202338000abdf7e09311c2a8a1</td>\n",
       "      <td>Coraopolis</td>\n",
       "      <td>PA</td>\n",
       "      <td>Allegheny</td>\n",
       "      <td>15108</td>\n",
       "      <td>40.49998</td>\n",
       "      <td>-80.19959</td>\n",
       "      <td>41524</td>\n",
       "      <td>...</td>\n",
       "      <td>7887.553</td>\n",
       "      <td>11643.190</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Customer_id                           Interaction  \\\n",
       "CaseOrder                                                     \n",
       "9996          B863060  a25b594d-0328-486f-a9b9-0567eb0f9723   \n",
       "9997          P712040  70711574-f7b1-4a17-b15f-48c54564b70f   \n",
       "9998          R778890  1d79569d-8e0f-4180-a207-d67ee4527d26   \n",
       "9999          E344109  f5a68e69-2a60-409b-a92f-ac0847b27db0   \n",
       "10000         I569847  bc482c02-f8c9-4423-99de-3db5e62a18d5   \n",
       "\n",
       "                                        UID        City State      County  \\\n",
       "CaseOrder                                                                   \n",
       "9996       39184dc28cc038871912ccc4500049e5     Norlina    NC      Warren   \n",
       "9997       3cd124ccd43147404292e883bf9ec55c      Milmay    NJ    Atlantic   \n",
       "9998       41b770aeee97a5b9e7f69c906a8119d7   Southside    TN  Montgomery   \n",
       "9999       2bb491ef5b1beb1fed758cc6885c167a       Quinn    SD  Pennington   \n",
       "10000      95663a202338000abdf7e09311c2a8a1  Coraopolis    PA   Allegheny   \n",
       "\n",
       "             Zip       Lat        Lng  Population  ... TotalCharge  \\\n",
       "CaseOrder                                          ...               \n",
       "9996       27563  36.42886  -78.23716        4762  ...    6850.942   \n",
       "9997        8340  39.43609  -74.87302        1251  ...    7741.690   \n",
       "9998       37171  36.36655  -87.29988         532  ...    8276.481   \n",
       "9999       57775  44.10354 -102.01590         271  ...    7644.483   \n",
       "10000      15108  40.49998  -80.19959       41524  ...    7887.553   \n",
       "\n",
       "          Additional_charges Item1  Item2  Item3  Item4 Item5 Item6 Item7  \\\n",
       "CaseOrder                                                                   \n",
       "9996                8927.642     3      2      2      3     4     3     4   \n",
       "9997               28507.150     3      3      4      2     5     3     4   \n",
       "9998               15281.210     3      3      3      4     4     2     3   \n",
       "9999                7781.678     5      5      3      4     4     3     4   \n",
       "10000              11643.190     4      3      3      2     3     6     4   \n",
       "\n",
       "           Item8  \n",
       "CaseOrder         \n",
       "9996           2  \n",
       "9997           4  \n",
       "9998           2  \n",
       "9999           3  \n",
       "10000          3  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the last 5 rows of the dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 49 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Customer_id         10000 non-null  object \n",
      " 1   Interaction         10000 non-null  object \n",
      " 2   UID                 10000 non-null  object \n",
      " 3   City                10000 non-null  object \n",
      " 4   State               10000 non-null  object \n",
      " 5   County              10000 non-null  object \n",
      " 6   Zip                 10000 non-null  int64  \n",
      " 7   Lat                 10000 non-null  float64\n",
      " 8   Lng                 10000 non-null  float64\n",
      " 9   Population          10000 non-null  int64  \n",
      " 10  Area                10000 non-null  object \n",
      " 11  TimeZone            10000 non-null  object \n",
      " 12  Job                 10000 non-null  object \n",
      " 13  Children            10000 non-null  int64  \n",
      " 14  Age                 10000 non-null  int64  \n",
      " 15  Income              10000 non-null  float64\n",
      " 16  Marital             10000 non-null  object \n",
      " 17  Gender              10000 non-null  object \n",
      " 18  ReAdmis             10000 non-null  object \n",
      " 19  VitD_levels         10000 non-null  float64\n",
      " 20  Doc_visits          10000 non-null  int64  \n",
      " 21  Full_meals_eaten    10000 non-null  int64  \n",
      " 22  vitD_supp           10000 non-null  int64  \n",
      " 23  Soft_drink          10000 non-null  object \n",
      " 24  Initial_admin       10000 non-null  object \n",
      " 25  HighBlood           10000 non-null  object \n",
      " 26  Stroke              10000 non-null  object \n",
      " 27  Complication_risk   10000 non-null  object \n",
      " 28  Overweight          10000 non-null  object \n",
      " 29  Arthritis           10000 non-null  object \n",
      " 30  Diabetes            10000 non-null  object \n",
      " 31  Hyperlipidemia      10000 non-null  object \n",
      " 32  BackPain            10000 non-null  object \n",
      " 33  Anxiety             10000 non-null  object \n",
      " 34  Allergic_rhinitis   10000 non-null  object \n",
      " 35  Reflux_esophagitis  10000 non-null  object \n",
      " 36  Asthma              10000 non-null  object \n",
      " 37  Services            10000 non-null  object \n",
      " 38  Initial_days        10000 non-null  float64\n",
      " 39  TotalCharge         10000 non-null  float64\n",
      " 40  Additional_charges  10000 non-null  float64\n",
      " 41  Item1               10000 non-null  int64  \n",
      " 42  Item2               10000 non-null  int64  \n",
      " 43  Item3               10000 non-null  int64  \n",
      " 44  Item4               10000 non-null  int64  \n",
      " 45  Item5               10000 non-null  int64  \n",
      " 46  Item6               10000 non-null  int64  \n",
      " 47  Item7               10000 non-null  int64  \n",
      " 48  Item8               10000 non-null  int64  \n",
      "dtypes: float64(7), int64(15), object(27)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the DataFrame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    10000\n",
      "Name: count, dtype: int64\n",
      "Total Duplicated Rows:  0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows. Count the number of True and False values returned by df.duplicated().\n",
    "print(df.duplicated().value_counts())\n",
    "\n",
    "# Display the count of duplicate rows\n",
    "print('Total Duplicated Rows: ', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is no need to treat duplicates as all rows are confirmed unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_id           10000\n",
       "Interaction           10000\n",
       "UID                   10000\n",
       "City                   6072\n",
       "State                    52\n",
       "County                 1607\n",
       "Zip                    8612\n",
       "Lat                    8588\n",
       "Lng                    8725\n",
       "Population             5951\n",
       "Area                      3\n",
       "TimeZone                 26\n",
       "Job                     639\n",
       "Children                 11\n",
       "Age                      72\n",
       "Income                 9993\n",
       "Marital                   5\n",
       "Gender                    3\n",
       "ReAdmis                   2\n",
       "VitD_levels            9976\n",
       "Doc_visits                9\n",
       "Full_meals_eaten          8\n",
       "vitD_supp                 6\n",
       "Soft_drink                2\n",
       "Initial_admin             3\n",
       "HighBlood                 2\n",
       "Stroke                    2\n",
       "Complication_risk         3\n",
       "Overweight                2\n",
       "Arthritis                 2\n",
       "Diabetes                  2\n",
       "Hyperlipidemia            2\n",
       "BackPain                  2\n",
       "Anxiety                   2\n",
       "Allergic_rhinitis         2\n",
       "Reflux_esophagitis        2\n",
       "Asthma                    2\n",
       "Services                  4\n",
       "Initial_days           9997\n",
       "TotalCharge            9997\n",
       "Additional_charges     9418\n",
       "Item1                     8\n",
       "Item2                     7\n",
       "Item3                     8\n",
       "Item4                     7\n",
       "Item5                     7\n",
       "Item6                     7\n",
       "Item7                     7\n",
       "Item8                     7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the number of unique values for each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values - Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detection and treatment of missing values begin by using `df.isnull().sum()`, which returns `True` if the value is null and `False` if the value is not null. `True` values are then summed and returned for each column.\n",
    "  \n",
    "- To keep things more efficient, a list of only those variables with missing values will be created by displaying only those columns with `missing values greater than 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found.\n",
      "Number of missing values per column:\n",
      "Series([], dtype: int64)\n",
      "Customer_id           False\n",
      "Interaction           False\n",
      "UID                   False\n",
      "City                  False\n",
      "State                 False\n",
      "County                False\n",
      "Zip                   False\n",
      "Lat                   False\n",
      "Lng                   False\n",
      "Population            False\n",
      "Area                  False\n",
      "TimeZone              False\n",
      "Job                   False\n",
      "Children              False\n",
      "Age                   False\n",
      "Income                False\n",
      "Marital               False\n",
      "Gender                False\n",
      "ReAdmis               False\n",
      "VitD_levels           False\n",
      "Doc_visits            False\n",
      "Full_meals_eaten      False\n",
      "vitD_supp             False\n",
      "Soft_drink            False\n",
      "Initial_admin         False\n",
      "HighBlood             False\n",
      "Stroke                False\n",
      "Complication_risk     False\n",
      "Overweight            False\n",
      "Arthritis             False\n",
      "Diabetes              False\n",
      "Hyperlipidemia        False\n",
      "BackPain              False\n",
      "Anxiety               False\n",
      "Allergic_rhinitis     False\n",
      "Reflux_esophagitis    False\n",
      "Asthma                False\n",
      "Services              False\n",
      "Initial_days          False\n",
      "TotalCharge           False\n",
      "Additional_charges    False\n",
      "Item1                 False\n",
      "Item2                 False\n",
      "Item3                 False\n",
      "Item4                 False\n",
      "Item5                 False\n",
      "Item6                 False\n",
      "Item7                 False\n",
      "Item8                 False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# The isnull() method creates a boolean DataFrame indicating which cells in df are null or missing values. \n",
    "# The sum() method then sums the number of True values in each column of the boolean DataFrame and returns a \n",
    "# new Series with the sums.\n",
    "null_cols = df.isnull().sum()\n",
    "\n",
    "#  Create a boolean Series indicating which columns have missing values. \n",
    "# Assigns only those values in null_cols that are greater than 0 to missing. (only rows with missing values)\n",
    "missing = null_cols > 0\n",
    "if missing.sum() == 0:\n",
    "    print('No missing values found.')\n",
    "# Print the count of missing values for each column with missing values, sorted in descending order\n",
    "print('Number of missing values per column:')\n",
    "print(null_cols[missing].sort_values(ascending=False))\n",
    "print(null_cols > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are no missing values in the dataset, so no further action is required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect and treat outliers \n",
    "\n",
    "- For variables that have numeric value, detection of outliers will be employeed. Given that one is not entierly sure if the distribution of the variables is normal, and because of the excellent visual information they provide, Boxlots and Histograms will be used to detect outliers ofver Z-scores. Variables with types that may contain outliers include:\n",
    "- Children\t\n",
    "- Age\t\n",
    "- Income\t\n",
    "- VitD_levels\t\n",
    "- Doc_visits\t\n",
    "- Full_meals_eaten\t\n",
    "- VitD_supp\t\n",
    "- Initial_days\t\n",
    "- TotalCharge\t\n",
    "- Additional_charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G & H: References\n",
    "\n",
    "- Western Governors University. (2023, December 21). D207 - Medical_clean Dataset. Retrieved from https://lrps.wgu.edu/provision/227079957\n",
    "\n",
    "- Western Governors University IT Department. (2023). R or Python? How to decide which programming language to learn. Retrieved from https://www.wgu.edu/online-it-degrees/programming-languages/r-or-python.html#\n",
    "\n",
    "- Datacamp. (2023, December 12). D207 - Exploratory Data Analysis. Retrieved from https://app.datacamp.com/learn/custom-tracks/custom-d207-exploratory-data-analysis \n",
    "\n",
    "- Sewell, Dr. (2023). WGU D207 Exploratory Data Analysis [Webinars]. WGU Webex. Accessed December, 2023. https://wgu.webex.com/webappng/sites/wgu/meeting/info/c4aca2eac546482880f1557c938abf40?siteurl=wgu&MTID=me73470c2eac9e863c6f47a3d5b6d2f26 \n",
    "\n",
    "- Seaborn Developers. (2023). seaborn.scatterplot — seaborn 0.11.2 documentation. Retrieved December 22, 2023, from https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "\n",
    "OLD ABOVE _ DELETE?KEEP? as needed.\n",
    "\n",
    "- Statology. (n.d.). *The Five Assumptions of Multiple Linear Regression*. Statology. Retrieved March 10, 2024, from www.statology.org/multiple-linear-regression-assumptions/\n",
    "\n",
    "- Pennsylvania State University. (n.d.). *5.3 - The Multiple Linear Regression Model*. STAT 501. Retrieved March 10, 2024, from online.stat.psu.edu/stat501/lesson/5/5.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "\n",
    "Beware of the following with your regression analysis:\n",
    "\n",
    "Overfitting can occur due to limited data points.\n",
    "\n",
    "Multicollinearity occurs when high association (correlation) with other IVs.\n",
    "\n",
    "P-values can be unreliable and coefficients swing wildly\n",
    "\n",
    "Check for pairwise correlations and high VIF (> 10)\n",
    "\n",
    "Tune your model with as many variables as practical. Forward, backward, stepwise\n",
    "    regression based on AIC, BIC, etc.\n",
    "ppoint 5 https://westerngovernorsuniversity-my.sharepoint.com/:p:/g/personal/william_sewell_wgu_edu/ERPQ0YpiQktOl-7YyAVnfLMBR5qeBh2cSv61VaJqe_aHKg?e=FjPhPz\n",
    "\n",
    "# Errata n notes\n",
    "\n",
    "I'm wrapping up task 1, and my research question is 'what factors influence the total charge a patient receives'. Total charge has a bimodal distribution that I did a log transform on which helped tremendously. Regarding my final reduced model, the RSE is pretty good, both residual normality and homoscedasticity are mostly there. Both have slight variance from expectations around the tails. For fun I decided to re run my code but filtered my data for patients staying less than a month and it improved my RSE, normality and homoscedasticity. Should I change my research question or keep it broad and just explain the limitations of outlier patients?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
